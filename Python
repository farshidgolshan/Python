# Import numpy, pandas and scipy libraries
import numpy as np
import pandas as pd
from scipy.stats import beta
import random

# Read the key answer list from the first excel file and store it in a dataframe
df_key = pd.read_excel('c://users//farsh//desktop//key_answers.xlsx')

# Read the real students answers from the second excel file and store it in another dataframe
df_real = pd.read_excel('c://users//farsh//desktop//real_answers.xlsx')

# Join the two dataframes on the subject and question columns and add a column for whether the student answer is correct or not by comparing it with the key answer
df_real = df_real.merge(df_key, on=['Subject', 'Question'], how='left')
df_real['Correct'] = df_real['Student Answer'] == df_real['Key Answer']

# Calculate the difficulty level of each question by counting the number of correct answers divided by the total number of answers for that question
df_difficulty = df_real.groupby(['Subject', 'Question'])['Correct'].mean().reset_index()
df_difficulty.columns = ['Subject', 'Question', 'Difficulty']

# Define the number of fake students and the desired percentage for each subject
n_fake = 24 # 6 times more than real students
desired_percentages = [0.75, 0.65, 0.85, 0.55, 0.45] # must be between 0 and 1

# Generate random answers for fake students based on the difficulty level of each question and the desired percentage for each subject
# You can use a probability distribution that takes into account both factors, such as a beta distribution or a logistic distribution
# You can also add some randomness to simulate wrong answers and unanswered questions

# Create a list of possible answers (0 to 4) and no answer (-1)
possible_answers = [-1, 0, 1, 2, 3, 4]

# Create a list comprehension to generate the fake data
fake_data = [
# Create a dictionary comprehension to store the fake student data for each subject and fake student
	{
# Assign a fake student ID using f-string
		'Student ID': f'Fake Student {fake_student + 1}',
		# Assign the subject name using f-string
		'Subject': f'Subject {subject + 1}',
		# Create another dictionary comprehension to assign the answer for each question for this subject and fake student
**{
			# Get the question name using f-string
			f'Question {question + 1}':# Add a comma here!
			# Generate a random answer for this question based on a weighted choice with probabilities proportional to difficulty level and desired percentage
			# You can change this to another distribution if you want
			random.choices(
			possible_answers,
			weights=[
			# Assign a higher weight for no answer if difficulty level is low or desired percentage is low
			(1 - difficulty) * (1 - percentage),
			# Assign a lower weight for wrong answers if difficulty level is high or desired percentage is high
difficulty * (1 - percentage) / 5,
difficulty * (1 - percentage) / 5,
difficulty * (1 - percentage) / 5,
difficulty * (1 - percentage) / 5,
difficulty * (1 - percentage) / 5,
# Assign a higher weight for correct answer if difficulty level is high and desired percentage is high
difficulty * percentage
]
)[0]
# Loop through each question for this subject using the number of questions from the difficulty dataframe
for question in range(df_difficulty[df_difficulty['Subject'] == f'Subject {subject + 1}'].shape[0])
}
}
# Loop through each subject using the desired percentages list
for subject, percentage in enumerate(desired_percentages)
# Loop through each fake student using the number of fake students
for fake_student in range(n_fake)
]

# Create a dataframe with fake students data
df_fake = pd.DataFrame(fake_data)

# Save the dataframe to an excel file
df_fake.to_excel('C://users//farsh//desktop//fake_answers.xlsx', index=False)


